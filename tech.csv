name,ring,quadrant,isNew,description
Cypress,adopt,tools,TRUE,"<p>We keep receiving positive feedback on ""post-Selenium"" web UI testing tools such as <strong><a href=""http://www.cypress.io/"">Cypress</a></strong>, <a href=""/radar/tools/testcafe"">TestCafe</a> and <a href=""/radar/languages-and-frameworks/puppeteer"">Puppeteer</a>. Running end-to-end tests can present challenges, such as the long duration of the running process, the flakiness of some tests and the challenges of fixing failures in CI when running tests in headless mode. Our teams have had very good experiences with Cypress by solving common issues such as lack of performance and long wait time for responses and resources to load. Cypress has become the tool of choice for end-to-end testing within our teams.</p>"
Terratest,assess,tools,TRUE,"<p>We widely use <a href=""/radar/tools/terraform"">Terraform</a> as code to configure a cloud infrastructure. <strong><a href=""https://github.com/gruntwork-io/terratest"">Terratest</a></strong> is a Golang library that makes it easier to write automated tests for infrastructure code. A test run creates real infrastructure components (such as servers, firewalls or load balancers), deploys applications on them and validates the expected behavior using Terratest. At the end of the test, Terratest can undeploy the apps and clean up resources. This makes it largely useful for end-to-end tests of your infrastructure in a real environment.</p>"
Handwritten CloudFormation,hold,tools,TRUE,"<p><a href=""https://aws.amazon.com/cloudformation/"">AWS CloudFormation</a> is a proprietary declarative language to provision AWS infrastructure as code. Handwriting CloudFormation files is often a default approach to bootstrap AWS infrastructure automation. Although this might be a sensible way to start a small project, our teams, and the industry at large, have found that <strong>handwritten CloudFormation</strong> simply does not scale as the infrastructure grows. Noticeable pitfalls of handwritten CloudFormation files for large projects include poor readability, lack of imperative constructs, limited parameter definition and usage, and lack of type checking. Addressing these shortfalls has led to a rich ecosystem of both open-source and custom tooling. We find <a href=""/radar/tools/terraform"">Terraform</a> a sensible default that not only addresses shortfalls of CloudFormation but also has an active community to add the latest AWS features and fix bugs. In addition to Terraform, you can choose from many other tools and languages, including <a href=""/radar/languages-and-frameworks/troposphere"">troposphere</a>, <a href=""https://github.com/cloudreach/sceptre"">sceptre</a>, <a href=""https://github.com/capitalone/stack-deployment-tool"">Stack Deployment Tool</a> and <a href=""/radar/platforms/pulumi"">Pulumi</a>.</p>"
Apollo,adopt,language-and-frameworks,TRUE,"<p>Our teams report that <strong><a href=""http://www.apollographql.com/client"">Apollo</a></strong> has become the library of choice when building a <a href=""/radar/languages-and-frameworks/react-js"">React</a> application that uses GraphQL to access data from a <a href=""/radar/techniques/bff-backend-for-frontends"">back-end</a> service. Although the Apollo project also provides a server framework and a GraphQL gateway, the Apollo client gets our attention because it simplifies the problem of binding UI components to data served by any GraphQL backend. Put simply, this means less code needs to be written than using REST backends and redux.</p>"
MockK,adopt,language-and-frameworks,TRUE,"<p><strong><a href=""https://mockk.io"">MockK</a></strong> is our go-to tool for mocks when writing tests for <a href=""/radar/languages-and-frameworks/kotlin"">Kotlin</a> applications. We like to use this library because of its first-class support for Kotlin language features such as <a href=""https://kotlinlang.org/docs/reference/coroutines-overview.html"">coroutines</a> or lambda blocks. As a native library, it helps our teams to write clean and concise code on testing Kotlin applications instead of using the inconvenient wrappers of Mockito or PowerMock.</p>"
TypeScript,adopt,language-and-frameworks,TRUE,"<p><strong><a href=""https://www.typescriptlang.org/"">TypeScript</a></strong>, a statically typed language and superset of JavaScript, has become our sensible default. Large-scale projects benefit most from the type safety. Our developers favor its minimal configuration management, well-integrated IDE support and its ability to refactor code safely and gradually adopt types. With its <a href=""https://definitelytyped.org/"">good repository</a> of TypeScript-type definitions at hand, we benefit from all the rich JavaScript libraries while gaining type safety.</p>"
Vapor,assess,language-and-frameworks,TRUE,"<p>We're strong proponents of <a href=""/radar/techniques/polyglot-programming"">polyglot programming</a> but recognize that in some cases it can make sense to focus on a single programming language. If you're heavily invested in Swift, most likely because of iOS development, and you find yourself looking for a technology to write server-side services, have a look at <strong><a href=""https://vapor.codes/"">Vapor</a></strong>, a modern web framework for Swift that has gained a fair amount of popularity.</p>"
Contentful,adopt,platforms,TRUE,"<p>Headless content management systems (CMSes) are becoming a common component of digital platforms. <a href=""http://www.contentful.com/""><strong>Contentful</strong></a> is a modern headless CMS that our teams have successfully integrated into their development workflows. We particularly like its API-first approach and implementation of <a href=""http://www.contentful.com/r/knowledgebase/cms-as-code/"">CMS as code</a>. It supports powerful content modeling primitives as code and content model evolution scripts, which allow it to be treated like other data store schemas and enable <a href=""http://martinfowler.com/articles/evodb.html"">evolutionary database design</a> practices to be applied to CMS development. Its robustness and a stream of new features, including a sandbox environment, have impressed our teams further and made Contentful our default choice in this space.</p>"
AWS Fargate,trial,platforms,TRUE,"<p><strong><a href=""http://aws.amazon.com/fargate/"">AWS Fargate</a></strong>, the docker-as-a-service option on <a href=""/radar/platforms/aws"">AWS</a>, is now widely available across regions. It's a great solution for situations in which teams want to run Docker containers, because <a href=""/radar/platforms/aws-lambda"">AWS Lambda</a> functions aren't powerful enough, without having to manage EC2 instances or Kubernetes clusters. Our teams report generally positive experiences with Fargate; however, the convenience of this managed service can come at a cost, in financial terms.</p>"
TimescaleDB,assess,platforms,TRUE,"<p>In previous Radars we've discussed <a href=""/radar/platforms/postgresql-for-nosql"">PostgreSQL for NoSQL</a>. PostgreSQL's maturity and extensibility have led to a steady stream of innovative persistence stores built on the Postgres engine. One that caught our attention is <strong><a href=""https://www.timescale.com/"">TimescaleDB</a></strong>, a database that allows fast writes and optimized queries over time-series data. Albeit not (yet) as full-featured as <a href=""/radar/platforms/influxdb"">InfluxDB</a>, TimescaleDB offers an alternative data model and querying capability. You should evaluate TimescaleDB if you have modest scalability needs, prefer to use SQL and appreciate the stability and familiar administrative interface that PostgreSQL offers.</p>"
Four key metrics,adopt,techniques,TRUE,"<p>The thorough <a href=""https://devops-research.com/research.html"">State of DevOps</a> reports have focused on data-driven and statistical analysis of high-performing organizations. The result of this multiyear research, published in <a href=""https://itrevolution.com/book/accelerate/"">Accelerate</a>, demonstrates a direct link between organizational performance and software delivery performance. The researchers have determined that only <strong>four key metrics</strong> differentiate between low, medium and high performers: lead time, deployment frequency, mean time to restore (MTTR) and change fail percentage. Indeed, we've found that these four key metrics are a simple and yet powerful tool to help leaders and teams focus on measuring and improving what matters. A good place to start is to instrument the build pipelines so you can capture the four key metrics and make the software delivery value stream visible. <a href=""https://www.gocd.org/"">GoCD pipelines,</a> for example, provide the ability to measure these four key metrics as a first-class citizen of the <a href=""https://www.gocd.org/analytics.html"">GoCD analytics</a>.</p>"
Micro frontends,adopt,techniques,TRUE,"<p>We've seen significant benefits from introducing <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we've also seen many teams create a frontend monolith — a large, entangled browser application that sits on top of the backend services — largely neutralizing the benefits of microservices. Since we first described <strong>micro frontends</strong> as a technique to address this issue, we've had almost universally positive experiences with the approach and have found a number of patterns to use micro frontends even as more and more code shifts from the server to the web browser. So far, <a href=""/radar/platforms/web-components-standard"">web components</a> have been elusive in this field, though.</p>"
Opinionated and automated code formatting,adopt,techniques,TRUE,"<p>For as long as we can remember, what style to use for formatting code has been a matter of personal taste, company policy and heated debate. Finally, the industry appears to be tiring of this endless argument and teams are freeing up surprisingly large amounts of time by forgoing these discussions and just adopting <strong>opinionated and automated code formatting</strong> tools. Even if you don't agree 100% with the opinions of the various tools, the benefits of focusing on what your code does rather than how it looks is something most teams should be able to get behind. <a href=""/radar/tools/prettier"">Prettier</a> has been getting our vote for JavaScript, but similar tools, such as <a href=""https://github.com/ambv/black"">Black</a> for Python, are available for many other languages and are increasingly being built-in as we see with <a href=""https://golang.org/cmd/gofmt/"">Golang</a> and <a href=""https://elixir-lang.org/blog/2018/01/17/elixir-v1-6-0-released/"">Elixir</a>. The key here is not to spend hours discussing which rules to enforce, but instead pick a tool that is opinionated, minimally configurable and automated — ideally as a pre-commit hook.</p>"
Polyglot programming,adopt,techniques,TRUE,"<p>We put <strong>polyglot programming</strong> on Trial in one of our first Radars to suggest that choosing the right language for the job could significantly boost productivity, and there were new language entrants that were worthy of consideration. We want to reraise this suggestion because we're seeing a new push to standardize language stacks by both developers and enterprises. While we acknowledge that placing no restrictions on language uses can create more problems than it solves, promoting a few languages that support different ecosystems or language features is important for both enterprises to accelerate processes and go live more quickly and developers to have the right tools to solve the problem at hand.</p>"
Secrets as a service,adopt,techniques,TRUE,"<p>Humans and machines use secrets throughout the value stream of building and operating software. The build pipelines need secrets to interface with secure infrastructures such as container registries, the applications use API keys as secrets to get access to business capabilities, and the service-to-service communications are secured using certificates and keys as secrets. You can set and retrieve these secrets in different ways. We've long cautioned developers about using source code management for storing secrets. We've recommended <a href=""/radar/techniques/decoupling-secret-management-from-source-code"">decoupling secret management from source code</a> and using tools such as <a href=""/radar/tools/git-secrets"">git-secrets</a> and <a href=""/radar/tools/talisman"">Talisman</a> to avoid storing secrets in the source code. We've been using <strong>secrets as a service</strong> as a default technique for storing and accessing secrets. With this technique you can use tools such as <a href=""/radar/tools/hashicorp-vault"">Vault</a> or <a href=""https://aws.amazon.com/kms/"">AWS Key Management Service (KMS)</a> to read/write secrets over an HTTPS endpoint with fine-grained levels of access control. Secrets as a service uses external identity providers such as <a href=""https://aws.amazon.com/iam/"">AWS IAM</a> to identify the actors who request access to secrets. Actors authenticate themselves with the secrets service. For this process to work, it's important to automate bootstrapping the identity of the actors, services and applications. Platforms based on <a href=""/radar/platforms/spiffe"">SPIFFE</a> have improved the automation of assigning identities to services.</p>"
Chaos Engineering,trial,techniques,FALSE,"<p>In the last year we've seen <strong>Chaos Engineering</strong> move from a much talked-about idea to an accepted, mainstream approach to improving and assuring distributed system resilience. As organizations large and small begin to implement Chaos Engineering as an operational process, we're learning how to apply these techniques safely at scale. The approach is definitely not for everyone, and to be effective and safe, it requires organizational support at scale. Industry acceptance and available expertise will definitely increase with the appearance of commercial services such as <a href=""/radar/tools/gremlin"">Gremlin</a> and deployment tools such as <a href=""/radar/tools/spinnaker"">Spinnaker</a> implementing some Chaos Engineering tools.</p>"
Container security scanning,trial,techniques,TRUE,"<p>The container revolution around <a href=""/radar/platforms/docker"">Docker</a> has massively reduced the friction in moving applications between environments, fueling increased adoption of continuous delivery and continuous deployments. The latter, especially, has blown a rather large hole in the traditional controls over what can go to production. The technique of <strong>container security scanning</strong> is a necessary response to this threat vector. Tools in the build pipeline automatically check containers flowing through the pipeline against known vulnerabilities. Since our first mention of this technique, the tool landscape has matured and the technique has proven useful on development efforts with our clients.</p>"
Continuous delivery for machine learning (CD4ML) models,trial,techniques,TRUE,"<p><strong>Continuous delivery for machine learning (CD4ML) models</strong> apply continuous delivery practices to developing machine learning models so that they are always ready for production. This technique addresses two main problems of traditional machine learning model development: long cycle time between training models and deploying them to production, which often includes manually converting the model to production-ready code; and using production models that had been trained with stale data.</p>

<p>A continuous delivery pipeline of a machine learning model has two triggers: (1) changes to the structure of the model and (2) changes to the training and test data sets. For this to work we need to both version <a href=""/radar/techniques/versioning-data-for-reproducible-analytics"">the data sets</a> and the model's source code. The pipeline often includes steps such as testing the model against the test data set, applying automatic conversion of the model (if necessary) with tools such as <a href=""https://www.h2o.ai/"">H2O</a>, and deploying the model to production to deliver value.</p>"
Crypto shredding,trial,techniques,FALSE,"<p>Maintaining proper control over sensitive data is difficult, especially when it's copied outside of a master system of record for backup and recovery purposes. <strong>Crypto shredding</strong> is the practice of rendering sensitive data unreadable by deliberately overwriting or deleting encryption keys used to secure that data. Considering there are systems, such as audit application or blockchain, that should not or could not delete historical records, this technique is quite useful for privacy protection and <a href=""https://www.thoughtworks.com/insights/blog/gdpr-it-s-time-rethink-your-approach-privacy"">GDPR</a> compliance.</p>"
Infrastructure configuration scanner,trial,techniques,TRUE,"<p>For some time now we've recommended that delivery teams take ownership of their entire stack, including infrastructure. This means increased responsibility in the delivery team itself for configuring the infrastructure in a safe, secure and compliant way. When adopting cloud strategies, most organizations default to a tightly locked-down and centrally managed configuration to reduce risk, but this also creates substantial productivity bottlenecks. An alternative approach is to allow teams to manage their own configuration and use an <strong>infrastructure configuration scanner</strong> to ensure the configuration is safe and secure. Options include open-source scanners such as <a href=""https://github.com/toniblyx/prowler"">prowler</a> for <a href=""/radar/platforms/aws"">AWS</a> and <a href=""/radar/tools/kube-bench"">kube-bench</a> for <a href=""/radar/platforms/kubernetes"">Kubernetes</a> installations. For more continuous detection, take a look at cloud platforms such as AWS Config Rules among other commercial services.</p>"
Service mesh,trial,techniques,TRUE,"<p><strong>Service mesh</strong> is an approach to operating a secure, fast and reliable microservices ecosystem. It has been an important stepping stone in making it easier to adopt microservices at scale. It offers discovery, security, tracing, monitoring and failure handling. It provides these cross-functional capabilities without the need for a shared asset such as an API gateway or baking libraries into each service. A typical implementation involves lightweight reverse-proxy processes, aka sidecars, deployed alongside each service process in a separate container. Sidecars intercept the inbound and outbound traffic of each service and provide cross-functional capabilities mentioned above. This approach has relieved the distributed service teams from building and updating the capabilities that the mesh offers as code in their services. This has lead to an even easier adoption of <a href=""/radar/techniques/polyglot-programming"">polyglot programming</a> in a microservices ecosystem. Our teams have been successfully using this approach with open source projects such as <a href=""/radar/platforms/istio"">Istio</a> and we will continue to monitor other open service mesh implementations such as <a href=""http://linkerd.io/"">Linkerd</a> closely.</p>"
Ethical OS,assess,techniques,TRUE,"<p>As developers at ThoughtWorks we're acutely aware of the ethics of the work we do. As society becomes ever more reliant on technology, it's important that we consider ethics when making decisions as software development teams. Several toolkits have emerged that can help us think through some of the future implications of the software we're building. They include <a href=""http://tarotcardsoftech.artefactgroup.com/"">Tarot Cards of Tech</a> and <strong><a href=""https://ethicalos.org/"">Ethical OS</a></strong>, which we've had good feedback on. Ethical OS is a thinking framework and a set of tools that drive discussions around the ethics of building software. The framework is a collaboration between the Institute for the Future and the Tech and Society Solutions Lab. It's based on a practical set of risk zones, such as addiction and the <a href=""https://eand.co/the-dopamine-economy-336b239272ef"">dopamine economy</a>, plus a number of scenarios to drive conversation and discussion.</p>"
Smart contracts,assess,techniques,TRUE,"<p>The more experience we gain with using distributed ledger technologies (DLTs), the more we encounter the rough edges around the current state of <strong><a href=""https://en.wikipedia.org/wiki/Smart_contract"">smart contracts</a></strong>. Committing automated, irrefutable, irreversible contracts on ledger sounds great in theory. The problems arise when you consider how to use modern software delivery techniques to developing them, as well as the differences between implementations. Immutable data is one thing, but immutable business logic is something else entirely! It's really important to think about whether to include logic in a smart contract. We've also found very different operational characteristics between different implementations. For example, even though contracts can evolve, different platforms support this evolution to a greater or lesser extent. Our advice is to think long and hard before committing business logic to a smart contract and to weigh the merits of the different platforms before you do.</p>"
Transfer learning for NLP,assess,techniques,TRUE,"<p>Transfer learning has been quite effective within the field of computer vision, speeding the time to train a model by reusing existing models. Those of us who work in machine learning are excited that the same techniques can be applied to natural language processing (NLP) with the publication of <a href=""https://arxiv.org/abs/1801.06146"">ULMFiT</a> and open source pretrained models and code examples. We think <strong>transfer learning for NLP</strong> will significantly reduce the effort to create systems dealing with text classification.</p>"
Wardley mapping,assess,techniques,TRUE,"<p>We're usually wary of covering diagrammatic techniques, but <strong><a href=""https://medium.com/wardleymaps"">Wardley mapping</a></strong> is an interesting approach to start conversations around the evolution of an organization's software estate. At their simplest, they're used to visualize the value chains that exist within an organization, starting with customers' needs and progressively plotting the different capabilities and systems used to deliver on those needs along with the evolution of those capabilities and systems. The value of this technique is the process of collaborating to create the maps rather than the artefact itself. We recommend getting the right people in the room to produce them, and then treat them as living, evolving things rather than a complete artefact.</p>"
Productionizing Jupyter Notebooks,hold,techniques,TRUE,"<p><a href=""/radar/tools/jupyter"">Jupyter Notebooks</a> have gained in popularity among data scientists who use them for exploratory analyses, early-stage development and knowledge sharing. This rise in popularity has led to the trend of <strong>productionizing Jupyter Notebooks</strong>, by providing the tools and support to execute them at scale. Although we wouldn't want to discourage anyone from using their tools of choice, we don't recommend using Jupyter Notebooks for building scalable, maintainable and long-lived production code — they lack effective version control, error handling, modularity and extensibility among other basic capabilities required for building scalable, production-ready code. Instead, we encourage developers and data scientists to work together to find solutions that empower data scientists to build production-ready machine learning models using <a href=""/radar/techniques/continuous-delivery-for-machine-learning-cd4ml-models"">continuous delivery</a> practices with the right programming frameworks. We caution against productionization of Jupyter Notebooks to overcome inefficiencies in continuous delivery pipelines for machine learning, or inadequate automated testing.</p>"
Puncturing encapsulation with change data capture,hold,techniques,TRUE,"<p><a href=""https://en.wikipedia.org/wiki/Change_data_capture"">Change data capture</a> (CDC) is a very powerful technique for pulling database changes out of a system and performing some actions on that data. One of the most popular ways of doing this is to use the database's transaction log to identify changes and then publish those changes directly onto an event bus that can be consumed by other services. This works very well for use cases such as <a href=""https://martinfowler.com/articles/break-monolith-into-microservices.html"">breaking monoliths into microservices</a> but when used for first-class integration between microservices, this leads to puncturing encapsulation and leaking the source service's data layer into the event contract. We've talked about <a href=""/radar/techniques/domain-scoped-events"">domain scoped events</a> and other techniques that emphasize the importance of having our events model our domain properly. We're seeing some projects use CDC for publishing row-level change events and directly consuming these events in other services. This <strong>puncturing of encapsulation with change data capture</strong> can be a slippery slope leading to fragile integrations and we would like to call this out with this blip.</p>"
Release train,hold,techniques,TRUE,"<p>We've seen organizations successfully move from very infrequent releases to a higher cadence by using the <strong>release train</strong> concept. The release train is a technique for coordinating releases across multiple teams or components that have runtime dependencies. All releases happen on a fixed and reliable schedule regardless of whether all expected features are ready (the train doesn't wait for you — if you miss it you wait for the next one). Although we wholeheartedly endorse discipline around regularly releasing and demoing working software, we've experienced serious drawbacks with the approach over the medium to long term as it reinforces temporal coupling around sequencing of changes and can degrade quality as teams rush to complete features. We prefer to focus on the architectural and organizational approaches necessary to support independent releases. Although the train can be a useful forcing function for speeding up slower teams, we've also seen it as imposing an upper limit on how quickly faster-moving teams can move. We believe that it is a technique that should be approached with a good degree of caution, if at all.</p>"
Templating in YAML,hold,techniques,TRUE,"<p>As infrastructures grow in complexity, so do the configuration files that define them. Tools such as <a href=""https://aws.amazon.com/cloudformation/"">AWS CloudFormation</a>, <a href=""/radar/platforms/kubernetes"">Kubernetes</a> and <a href=""/radar/tools/helm"">Helm</a> expect configuration files in JSON or YAML syntax, presumably in an attempt to make them easy to write and process. However, in most cases, teams quickly reach the point where they have some parts that are similar but not quite the same, for example, when the same service must be deployed in different regions with a slightly different setup. For such cases tools offer <strong>templating in YAML</strong> (or JSON), which has caused a huge amount of <a href=""https://leebriggs.co.uk/blog/2019/02/07/why-are-we-templating-yaml.html"">frustration with practitioners</a>. The problem is that the syntax of JSON and YAML requires all sorts of awkward compromises to graft templating features such as conditionals and loops into the files. We recommend using an API from a programming language instead or, when this is not an option, a templating system in a programming language, either a general-purpose language such as Python or something specialized such as <a href=""https://jsonnet.org/"">Jsonnet</a>.</p>"
